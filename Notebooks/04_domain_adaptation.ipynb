{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b075f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import entropy\n",
    "import shap\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82fb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"C:/Users/LENOVO/Desktop/ByteBuzz/Data/final_dataset.csv\"\n",
    "MODEL_DIR = r\"C:/Users/LENOVO/Desktop/ByteBuzz/Models\"\n",
    "RESULTS_DIR = r\"C:/Users/LENOVO/Desktop/ByteBuzz/results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "BASELINE_CSV = os.path.join(RESULTS_DIR, \"baseline_results.csv\")\n",
    "KD_CSV = os.path.join(RESULTS_DIR, \"kd_results.csv\")\n",
    "CONTRAST_CSV = os.path.join(RESULTS_DIR, \"contrastive_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdcad946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: (1448, 28)\n"
     ]
    }
   ],
   "source": [
    "def safe_read_csv(p):\n",
    "    return pd.read_csv(p) if os.path.exists(p) else None\n",
    "\n",
    "def print_row(r):\n",
    "    print(f\"{r['Modality']:<6} | Acc: {r['Acc']:.3f} | F1: {r['F1']:.3f} | ROC-AUC: {r.get('ROC_AUC', np.nan):.3f}\")\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}. Please regenerate step2.3_final_dataset.csv\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d7b72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature counts: {'EEG': 7, 'EYE': 3, 'GSR': 4, 'TIVA': 5, 'IVT': 6}\n"
     ]
    }
   ],
   "source": [
    "# modality columns detection (per-modality PCA columns)\n",
    "EEG_cols  = [c for c in df.columns if c.startswith(\"EEG_PC\")]\n",
    "EYE_cols  = [c for c in df.columns if c.startswith(\"EYE_PC\")]\n",
    "GSR_cols  = [c for c in df.columns if c.startswith(\"GSR_PC\")]\n",
    "IVT_cols  = [c for c in df.columns if c.startswith(\"IVT_PC\")]\n",
    "TIVA_cols = [c for c in df.columns if c.startswith(\"TIVA_PC\")]\n",
    "\n",
    "modalities = {\n",
    "    \"EEG\": EEG_cols,\n",
    "    \"EYE\": EYE_cols,\n",
    "    \"GSR\": GSR_cols,\n",
    "    \"TIVA\": TIVA_cols,\n",
    "    \"IVT\": IVT_cols\n",
    "}\n",
    "\n",
    "print(\"Feature counts:\", {k: len(v) for k,v in modalities.items()})\n",
    "\n",
    "y = df[\"Label\"].values\n",
    "\n",
    "def eval_model_on_modality(model, X, y):\n",
    "    preds = model.predict(X)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    f1 = f1_score(y, preds, average=\"weighted\")\n",
    "    roc = None\n",
    "    if hasattr(model, \"predict_proba\") and len(np.unique(y))==2:\n",
    "        try:\n",
    "            prob = model.predict_proba(X)[:,1]\n",
    "            roc = roc_auc_score(y, prob)\n",
    "        except Exception:\n",
    "            roc = None\n",
    "    return acc, f1, roc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6962577",
   "metadata": {},
   "source": [
    "#Baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0476d4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded baseline CSV\n",
      "\n",
      "Baseline Results:\n",
      "EEG    | Acc: 0.859 | F1: 0.837 | ROC-AUC: 0.896\n",
      "EYE    | Acc: 0.945 | F1: 0.943 | ROC-AUC: 0.958\n",
      "GSR    | Acc: 0.950 | F1: 0.948 | ROC-AUC: 0.956\n",
      "TIVA   | Acc: 0.947 | F1: 0.946 | ROC-AUC: 0.948\n"
     ]
    }
   ],
   "source": [
    "baseline_df = safe_read_csv(BASELINE_CSV)\n",
    "if baseline_df is None:\n",
    "    rows = []\n",
    "    # EEG teacher\n",
    "    teacher_paths = [\n",
    "        os.path.join(MODEL_DIR, \"teacher_eeg_xgb.pkl\"),\n",
    "        os.path.join(MODEL_DIR, \"teacher_eeg.pkl\"),\n",
    "        os.path.join(MODEL_DIR, \"eeg_teacher.pkl\"),\n",
    "    ]\n",
    "    teacher_path = next((p for p in teacher_paths if os.path.exists(p)), None)\n",
    "    if teacher_path and len(EEG_cols) > 0:\n",
    "        teacher = joblib.load(teacher_path)\n",
    "        X = df[EEG_cols].values\n",
    "        acc, f1, roc = eval_model_on_modality(teacher, X, y)\n",
    "        rows.append({\"Modality\":\"EEG\",\"Acc\":acc,\"F1\":f1,\"ROC_AUC\": roc})\n",
    "    else:\n",
    "        print(\"Teacher model not found, skipping teacher baseline.\")\n",
    "\n",
    "    # Student models\n",
    "    student_map = {\n",
    "        \"EYE\": [\"student_eye_rf.pkl\",\"student_eye.pkl\",\"eye_student.pkl\"],\n",
    "        \"GSR\": [\"student_gsr_rf.pkl\",\"student_gsr.pkl\",\"gsr_student.pkl\"],\n",
    "        \"TIVA\": [\"student_tiva_rf.pkl\",\"student_tiva.pkl\",\"tiva_student.pkl\"]\n",
    "    }\n",
    "    for mod, patlist in student_map.items():\n",
    "        path = next((os.path.join(MODEL_DIR, p) for p in patlist if os.path.exists(os.path.join(MODEL_DIR, p))), None)\n",
    "        if path and len(modalities[mod]) > 0:\n",
    "            model = joblib.load(path)\n",
    "            X = df[modalities[mod]].values\n",
    "            acc,f1,roc = eval_model_on_modality(model, X, y)\n",
    "            rows.append({\"Modality\":mod,\"Acc\":acc,\"F1\":f1,\"ROC_AUC\":roc})\n",
    "        else:\n",
    "            print(f\"No baseline model found for {mod} or missing features.\")\n",
    "\n",
    "    baseline_df = pd.DataFrame(rows)\n",
    "    baseline_df.to_csv(BASELINE_CSV, index=False)\n",
    "    print(\"Saved baseline_results.csv\")\n",
    "else:\n",
    "    print(\"Loaded baseline CSV\")\n",
    "\n",
    "print(\"\\nBaseline Results:\")\n",
    "if not baseline_df.empty:\n",
    "    for _,r in baseline_df.iterrows(): print_row(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c174535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 2892/2896 [02:26<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved kd_results.csv\n",
      "\n",
      "KD Results:\n",
      "EYE    | Acc: 0.945 | F1: 0.943 | ROC-AUC: 0.958\n",
      "GSR    | Acc: 0.950 | F1: 0.948 | ROC-AUC: 0.956\n",
      "TIVA   | Acc: 0.947 | F1: 0.946 | ROC-AUC: 0.948\n",
      "\n",
      "=== SHAP Top Features per KD Model ===\n",
      "\n",
      "EYE:\n",
      "   Feature  Mean_Abs_SHAP\n",
      "2  EYE_PC3       0.081395\n",
      "0  EYE_PC1       0.072252\n",
      "1  EYE_PC2       0.068678\n",
      "\n",
      "GSR:\n",
      "   Feature  Mean_Abs_SHAP\n",
      "1  GSR_PC2       0.079207\n",
      "0  GSR_PC1       0.066688\n",
      "2  GSR_PC3       0.050288\n",
      "3  GSR_PC4       0.048604\n",
      "\n",
      "TIVA:\n",
      "    Feature  Mean_Abs_SHAP\n",
      "0  TIVA_PC1       0.057369\n",
      "3  TIVA_PC4       0.047802\n",
      "1  TIVA_PC2       0.044521\n",
      "2  TIVA_PC3       0.043569\n",
      "4  TIVA_PC5       0.041678\n"
     ]
    }
   ],
   "source": [
    "# 2) KD results + SHAP interpretability\n",
    "# -------------------------\n",
    "kd_df = safe_read_csv(KD_CSV)\n",
    "shap_summary = {}  # initialize outside\n",
    "if kd_df is None:\n",
    "    rows = []\n",
    "    kd_names = {\n",
    "        \"EYE\": [\"student_eye_kd.pkl\",\"student_eye_kd.pkl\"],\n",
    "        \"GSR\": [\"student_gsr_kd.pkl\",\"student_gsr_kd.pkl\"],\n",
    "        \"TIVA\": [\"student_tiva_kd.pkl\",\"student_tiva_kd.pkl\"]\n",
    "    }\n",
    "\n",
    "    for mod, patlist in kd_names.items():\n",
    "        path = next((os.path.join(MODEL_DIR, p) for p in patlist if os.path.exists(os.path.join(MODEL_DIR, p))), None)\n",
    "        if path and len(modalities[mod]) > 0:\n",
    "            model = joblib.load(path)\n",
    "            X = df[modalities[mod]].values\n",
    "            acc,f1,roc = eval_model_on_modality(model, X, y)\n",
    "            rows.append({\"Modality\":mod,\"Acc\":acc,\"F1\":f1,\"ROC_AUC\":roc})\n",
    "\n",
    "            # SHAP interpretability (robust)\n",
    "            try:\n",
    "                explainer = shap.Explainer(model, X)\n",
    "                shap_values = explainer(X)\n",
    "                shap_vals = np.mean(np.abs(shap_values.values), axis=(0, -1))  # 1D for any output\n",
    "                shap_df = pd.DataFrame({\n",
    "                    \"Feature\": modalities[mod],\n",
    "                    \"Mean_Abs_SHAP\": shap_vals\n",
    "                }).sort_values(by=\"Mean_Abs_SHAP\", ascending=False)\n",
    "                shap_summary[mod] = shap_df.head(10)\n",
    "            except Exception as e:\n",
    "                print(f\"SHAP computation failed for {mod}: {e}\")\n",
    "        else:\n",
    "            print(f\"No KD model found for {mod} or missing features.\")\n",
    "\n",
    "    kd_df = pd.DataFrame(rows)\n",
    "    kd_df.to_csv(KD_CSV, index=False)\n",
    "    print(\"Saved kd_results.csv\")\n",
    "else:\n",
    "    print(\"Loaded kd CSV\")\n",
    "\n",
    "print(\"\\nKD Results:\")\n",
    "if not kd_df.empty:\n",
    "    for _,r in kd_df.iterrows(): print_row(r)\n",
    "\n",
    "# Print SHAP top features\n",
    "print(\"\\n=== SHAP Top Features per KD Model ===\")\n",
    "for mod, df_shap in shap_summary.items():\n",
    "    print(f\"\\n{mod}:\")\n",
    "    print(df_shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb27511d",
   "metadata": {},
   "source": [
    "#Contrastive results + domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86db2a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrastive files missing/skipping for EYE\n",
      "Contrastive files missing/skipping for GSR\n",
      "Contrastive files missing/skipping for TIVA\n",
      "Contrastive files missing/skipping for IVT\n",
      "Saved contrastive_results.csv\n",
      "\n",
      "Contrastive Results:\n"
     ]
    }
   ],
   "source": [
    "contrast_df = safe_read_csv(CONTRAST_CSV)\n",
    "if contrast_df is None:\n",
    "    rows = []\n",
    "    pairs = [(\"EYE\",\"eeg2eye\"), (\"GSR\",\"eeg2gsr\"), (\"TIVA\",\"eeg2tiva\"), (\"IVT\",\"eeg2ivt\")]\n",
    "    for mod, pair in pairs:\n",
    "        enc_t_path = os.path.join(MODEL_DIR, f\"{pair}_enc_t.pth\")\n",
    "        proj_t_path = os.path.join(MODEL_DIR, f\"{pair}_proj_t.pth\")\n",
    "        scaler_t_path = os.path.join(MODEL_DIR, f\"{pair}_scaler_t.pkl\")\n",
    "        if os.path.exists(enc_t_path) and os.path.exists(proj_t_path) and os.path.exists(scaler_t_path) and len(modalities[mod])>0:\n",
    "            # load scaler and transform\n",
    "            scaler_t = joblib.load(scaler_t_path)\n",
    "            Xt = df[modalities[mod]].fillna(0).values\n",
    "            Xt_s = scaler_t.transform(Xt)\n",
    "\n",
    "            # RandomForest evaluation\n",
    "            clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "            Xtr, Xte, ytr, yte = train_test_split(Xt_s, y, test_size=0.2, stratify=y, random_state=42)\n",
    "            clf.fit(Xtr, ytr)\n",
    "            preds = clf.predict(Xte)\n",
    "            acc = accuracy_score(yte, preds)\n",
    "            f1 = f1_score(yte, preds, average=\"weighted\")\n",
    "            rows.append({\"Modality\":mod,\"Acc\":acc,\"F1\":f1,\"ROC_AUC\":None})\n",
    "\n",
    "            # Domain adaptation metrics\n",
    "            try:\n",
    "                enc_state = torch.load(enc_t_path, map_location=\"cpu\")\n",
    "                Xt_tensor = torch.tensor(Xt_s.astype(np.float32))\n",
    "                emb_mean = Xt_tensor.mean(dim=0).numpy()\n",
    "                eeg_mean = df[EEG_cols].fillna(0).values.mean(axis=0)\n",
    "                cos_sim = 1 - cosine(emb_mean, eeg_mean)\n",
    "                p = emb_mean / emb_mean.sum()\n",
    "                q = eeg_mean / eeg_mean.sum()\n",
    "                kl_div = entropy(p + 1e-10, q + 1e-10)\n",
    "                print(f\"{mod}: Cosine sim={cos_sim:.3f}, KL div={kl_div:.3f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Domain adaptation metric error for {mod}: {e}\")\n",
    "        else:\n",
    "            print(f\"Contrastive files missing/skipping for {mod}\")\n",
    "\n",
    "    contrast_df = pd.DataFrame(rows)\n",
    "    contrast_df.to_csv(CONTRAST_CSV, index=False)\n",
    "    print(\"Saved contrastive_results.csv\")\n",
    "else:\n",
    "    print(\"Loaded contrastive CSV\")\n",
    "\n",
    "print(\"\\nContrastive Results:\")\n",
    "if not contrast_df.empty:\n",
    "    for _,r in contrast_df.iterrows(): print_row(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5982f",
   "metadata": {},
   "source": [
    "#Combined comparison & interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7c4ae44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Combined Results ===\n",
      "               Acc                  F1          \n",
      "Method    Baseline        KD  Baseline        KD\n",
      "Modality                                        \n",
      "EEG       0.859116       NaN  0.836767       NaN\n",
      "EYE       0.944751  0.944751  0.943180  0.943180\n",
      "GSR       0.949586  0.949586  0.948381  0.948381\n",
      "TIVA      0.946823  0.946823  0.945621  0.945621\n",
      "\n",
      "=== Interpretation ===\n",
      "EEG: Best method = Baseline (Acc=0.859, F1=0.837)\n",
      "EYE: Best method = Baseline (Acc=0.945, F1=0.943)\n",
      "GSR: Best method = Baseline (Acc=0.950, F1=0.948)\n",
      "TIVA: Best method = KD (Acc=0.947, F1=0.946)\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for df_, name in [(baseline_df, \"Baseline\"), (kd_df, \"KD\"), (contrast_df, \"Contrastive\")]:\n",
    "    if df_ is not None and not df_.empty:\n",
    "        dfs.append(df_.assign(Method=name))\n",
    "\n",
    "if dfs:\n",
    "    combined = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "    combined.to_csv(os.path.join(RESULTS_DIR,\"combined_results_all.csv\"), index=False)\n",
    "\n",
    "    print(\"\\n=== Combined Results ===\")\n",
    "    print(combined.pivot_table(index=\"Modality\", columns=\"Method\", values=[\"Acc\",\"F1\"], aggfunc='first'))\n",
    "\n",
    "    print(\"\\n=== Interpretation ===\")\n",
    "    for mod in combined[\"Modality\"].unique():\n",
    "        sub = combined[combined[\"Modality\"]==mod]\n",
    "        if sub.empty: continue\n",
    "        best = sub.loc[sub[\"F1\"].idxmax()]\n",
    "        print(f\"{mod}: Best method = {best['Method']} (Acc={best['Acc']:.3f}, F1={best['F1']:.3f})\")\n",
    "else:\n",
    "    print(\"⚠️ No results DataFrames available to combine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a25102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
